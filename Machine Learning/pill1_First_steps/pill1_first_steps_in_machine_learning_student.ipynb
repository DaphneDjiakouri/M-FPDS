{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The machine learning pipeline\n",
    "\n",
    "Modeling churn means to understand what keeps the customer engaged to our product. Its analysis goal is to predict or describe the **churn rate** i.e. the rate at which customer leave or cease the subscription to a service. Its value lies in the fact that engaging new customers is often more costly than retaining existing ones. For that reason subscription business-based companies usually have proactive policies towards customer retention.\n",
    "\n",
    "In this case study, we aim at building a machine learning based model for customer churn prediction on data from a Telecom company. Each row on the dataset represents a subscribing telephone customer. Each column contains customer attributes such as phone number, call minutes used during different times of day, charges incurred for services, lifetime account duration, and whether or not the customer is still a customer.\n",
    "\n",
    "This case is partially inspired in Eric Chiang's analysis of churn rate. Data is available from the University of California Irvine machine learning repositories data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    " + Implement a full machine learning pipeline.\n",
    " + Understand the concepts of training, validation, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dl=pd.read_csv('./files/churn_curated_numerical.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dl.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.pie(np.c_[len(y)-np.sum(y),np.sum(y)][0],labels=['No Churn','Churn'],colors=['r','g'],shadow=True,autopct ='%.2f' )\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Observe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(X,axis=0)\n",
    "print(np.var(X,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem in Scikit-Learn is modeled as follows:\n",
    "\n",
    "+ Input data is structured in Numpy arrays. The size of the array is expected to be [n_samples, n_features]:\n",
    "\n",
    "    + *n_samples*: The number of samples ($N$): each sample is an item to process (e.g. classify). A sample can be a document, a picture, a sound, a video, an astronomical object, a row in database or CSV file, or whatever you can describe with a fixed set of quantitative traits.\n",
    "  \n",
    "    + *n_features*: The number of features ($d$) or distinct traits that can be used to describe each item in a quantitative manner. Features are generally real-valued, but may be boolean, discrete-valued or even cathegorical.\n",
    "\n",
    "$${\\rm feature~matrix:} {\\bf X}~=~\\left[\n",
    "\\begin{matrix}\n",
    "x_{11} & x_{12} & \\cdots & x_{1d}\\\\\n",
    "x_{21} & x_{22} & \\cdots & x_{2d}\\\\\n",
    "x_{31} & x_{32} & \\cdots & x_{3d}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_{N1} & x_{N2} & \\cdots & x_{Nd}\\\\\n",
    "\\end{matrix}\n",
    "\\right]$$\n",
    "\n",
    "$${\\rm label~vector:} {\\bf y}~=~ [y_1, y_2, y_3, \\cdots y_N]$$\n",
    "    \n",
    "\n",
    "The number of features must be fixed in advance. However it can be very high dimensional (e.g. millions of features) with most of them being zeros for a given sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit a decision tree (you can find it in the module sklearn.tree and the name is DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the data you used for training/fiting the classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat[100],y[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px\"><b>EXERCISE:</b> We need a measure of how well the classifier is performing. `yhat` is a list and our target outcome `y`is also a list. Create a measure of accuracy. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sensible way of measuring the goodness of a classifier is measuring the error rate, i.e. the number of times the classifier fails divided by the total number of elements.\n",
    "\n",
    "$$err = \\frac{1}{N}\\sum \\mathbb{1}_{\\tilde{y}!=y}$$\n",
    "\n",
    "where $\\mathbb{1}_{\\text{cond}}$ is the indicator function given a condition, $\\text{cond}$, defined as \n",
    "\n",
    "$$\\mathbb{1}_{\\text{cond}}=\\left \\{\\begin{align} 1 & \\quad\\text{if cond = True}\\\\ 0 & \\quad\\text{otherwise} \\end{align}\\right.$$\n",
    "Alternatively, we can report the accuracy, defined as the rate of success\n",
    "\n",
    "$$acc = \\frac{1}{N}\\sum \\mathbb{1}_{\\tilde{y}==y}.$$\n",
    "\n",
    "Observe that $acc = 1-err$.\n",
    "\n",
    "`sklearn` reports this result using the method from module `metrics`, `.accuracy_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style=\"border-radius:10px\"> <b>QUESTION:</b> Is this a good result?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style=\"border-radius:10px\">  BACK TO SLIDES!!!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data set.\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the data format.\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# The original digit has been flattened, so we reshape it back to its original form\n",
    "# Check the dimensionality of the data, e.g. the first element in the data set X[0]\n",
    "print (X[0].shape)\n",
    "print (X[0])\n",
    "\n",
    "# Reshape it to 8x8 to recover the original image\n",
    "print (X[0].reshape((8,8)))\n",
    "\n",
    "\n",
    "# Show the image using scikit.image package\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[2].reshape((8,8)),cmap=\"gray\",interpolation=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize some of the data.\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(8, 12, subplot_kw={'xticks':[], 'yticks':[]})\n",
    "for i in range(ax.size):\n",
    "    ax.flat[i].imshow(digits.data[i].reshape(8, 8),\n",
    "                      cmap=plt.cm.binary)\n",
    "fig.set_size_inches((10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style=\"border-radius:10px\"> <b>DISCUSS THE FOLLOWING KNOWLEDGE REPRESENTATION:</b> \n",
    "<p>    \n",
    "(A) We are asked to develop a product for automatic translation of text from a document. \n",
    "<p>\n",
    "(B) We are asked to develop a product similar to Shazzam(tm). This is, recognize the name of a song given a small sample of the music.*\n",
    "<p>\n",
    "Discuss and describe a posible feature vector for this problem with your partner.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More intuition about the data: The feature space\n",
    "\n",
    "Data is usually gathered as raw values. In the case of the digits dataset the gray values of the image. However, we can use domain knowledge we may consider important in order to discriminate the different classes. Take for instance two very simple derived features: horizontal, vertical symmetry and area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io as io\n",
    "\n",
    "tmp = X[7].reshape((8,8))    \n",
    "sym = tmp*tmp[:,::-1]\n",
    "io.imshow(tmp)\n",
    "io.show()\n",
    "io.imshow(tmp[:,::-1])\n",
    "io.show()\n",
    "\n",
    "import numpy as np\n",
    "Xnew = np.zeros((y.shape[0],3))\n",
    "for i in range(y.shape[0]):\n",
    "    area = sum(X[i])\n",
    "    tmp = X[i].reshape((8,8))    \n",
    "    symH = tmp*tmp[:,::-1]\n",
    "    symV = tmp*tmp[::-1,:]\n",
    "    \n",
    "    Xnew[i,:]=[sum(symH.flatten()), area, sum(symV.flatten())]\n",
    "\n",
    "print (Xnew)\n",
    "print (Xnew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "idxA = y==0\n",
    "idxB = y==6\n",
    "\n",
    "feature1 = 0\n",
    "feature2 = 1\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(Xnew[idxA, feature1], Xnew[idxA,feature2], c='green',alpha=0.8)\n",
    "plt.scatter(Xnew[idxB, feature1], Xnew[idxB,feature2], c='red',alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\"> **Exercise** Change feature1 and feature2 axis $\\in \\{0,1,2\\}$ and select the most suitable view for classification purposes. Why did you select that view?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of using knowledge domain information in order to create discriminant features is called <span style=\"color:red\">feature extraction</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data vs feature extraction\n",
    "\n",
    "**Raw data**\n",
    "\n",
    "Advantages:\n",
    "\n",
    "+ No domain specific knowledge is required.\n",
    "\n",
    "Drawbacks:\n",
    "\n",
    "+ Highly redundant in many cases and usually span very large dimensional spaces.\n",
    "+ Unknown discriminability.\n",
    "\n",
    "**Feature extraction**\n",
    "\n",
    "Advantages:\n",
    "\n",
    "+ Attempt to capture discriminant information in the data.\n",
    "+ Lower dimensionality and complexity.\n",
    "\n",
    "Drawbacks: \n",
    "\n",
    "+ Domain specific knowledge is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style=\"border-radius:10px\"> <b>ACTION:</b> BACK TO SLIDES</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dl=pd.read_csv('./files/churn_curated_numerical.csv',header=None)\n",
    "data = np.asarray(dl)\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X,y)\n",
    "yhat = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us change the model, and check what we obtain with a different classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X,y)\n",
    "yhat = clf.predict(X)\n",
    "metrics.accuracy_score(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style=\"border-radius:10px\"> <b>QUESTION:</b> This is a pretty good result, isn't it?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./files/i-dont-know-rick-it-looks-fake.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style=\"border-radius:10px\"> <b>QUESTION:</b> Is this the value we expect to have when we apply this method in production?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real applications we will train a classifier on a given data set but then apply the classifier to unseen data. Let us simulate this process by spliting the data set in two sets. We will call data we use for fiting the classifier training and data used for assessing the performance, test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px\"><b>EXERCISE:</b> Split the data set 70% for training purposes and the rest for test purposes. You should end up with four variables `X_train`, `y_train`, `X_test`, `y_test`. <p>\n",
    "<b>OTHER REQUIREMENTS:</b> Reshuffle data using a permutation of the indexes (`np.random.permutation(...)`) and set the seed of the random number generator using `np.random.seed(42)`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in training and set, use the module cross_validation, train_test_split , use random_state=42 as an argument for reproductibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "yhat = clf.predict(X_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y_train,yhat)\n",
    "\n",
    "yhat_test = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test,yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try a new algorithm, nearest neighbor, with parameter n_neighbors = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "yhat = clf.predict(X_train)\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y_train,yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y_test,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style=\"border-radius:10px\"> <b>QUESTION:</b> Is this a good result?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT SNOOPING CODE\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train_scaled,y_train)\n",
    "yhat = clf.predict(X_train_scaled)\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y_train,yhat)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "yhat = clf.predict(X_test_scaled)\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y_test,yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train_scaled,y_train)\n",
    "yhat = clf.predict(X_train_scaled)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_train,yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "yhat = clf.predict(X_test_scaled)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is ok, but how consistent is it? Maybe we have been lucky with the train-test partion. We can repeat this process for different values of the random_state (or just use random permutations) and report the average result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px\"><b>EXERCISE:</b> We want a vector of accuracies, `acc`, of shape (10,1) with the values of testing a 1-NN classifier on a `train_size=0.7` for the different random_states stored in the array `r_state`. Use `sklearn.cross_validation.train_test_split` function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_state = [0,1,2,3,4,5,42,43,44,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your code with the following visualization code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.boxplot(acc)\n",
    "plt.scatter(np.ones(acc.shape)+0.01*np.random.normal(size=(10,1)),acc,alpha = 0.5,color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px\"> <b>QUIZ:</b> Report the average accuracy.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My code\n",
    "value = np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(value-0.8691)<0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style=\"border-radius:10px\"> <b>ACTION:</b> BACK TO SLIDES</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection (I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried a 1-Nearest Neighbors classifiers but we could try also different values for the Nearest Neighbors. The selection of a model between different alternatives is called model selection. We can use the same strategy as before and report accuracies for the three models. Let us do it comparintg 1-NN, 3-NN and a DecisionTree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px\"><b>EXERCISE:</b> We want a matrix of accuracies, `acc`, of shape (10,3) with the values of testing a decision tree, a 1-NN, and a 3-NN classifier on a `train_size=0.7` for the different random_states stored in the array `r_state`. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My code\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "r_state = [0,1,2,3,4,5,42,43,44,45]\n",
    "\n",
    "acc = np.zeros((len(r_state),3))\n",
    "\n",
    "for i in range(len(r_state)):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, random_state=r_state[i])\n",
    "    \n",
    "    #Your code here\n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,1] = metrics.accuracy_score(y_test,yhat_nn1)\n",
    "    acc[i,2] = metrics.accuracy_score(y_test,yhat_nn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My code\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "r_state = [0,1,2,3,4,5,42,43,44,45]\n",
    "\n",
    "acc = np.zeros((len(r_state),3))\n",
    "\n",
    "for i in range(len(r_state)):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, random_state=r_state[i])\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "\n",
    "    tr = tree.DecisionTreeClassifier()\n",
    "    tr.fit(X_train_scaled,y_train)    \n",
    "    nn1 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "    nn1.fit(X_train_scaled,y_train)\n",
    "    nn3 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "    nn3.fit(X_train_scaled,y_train)\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    yhat_tr = tr.predict(X_test_scaled)\n",
    "    yhat_nn1 = nn1.predict(X_test_scaled)\n",
    "    yhat_nn3 = nn3.predict(X_test_scaled)\n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,1] = metrics.accuracy_score(y_test,yhat_nn1)\n",
    "    acc[i,2] = metrics.accuracy_score(y_test,yhat_nn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.boxplot(acc)\n",
    "plt.scatter(np.tile(np.array([1,2,3]),(10,1))+0.01*np.random.normal(size=(10,3)),acc,alpha = 0.5,color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px\" ><b>QUIZ:</b > What is the best of the three methods?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px\"><b>QUIZ:</b> What is the expected accuracy of the selected method in exploitation over unseen data? </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style = \"border-radius:10px\"><b>EXERCISE:</b> The  `breast_cancer` dataset from `datasets` (check `load_breast_cancer`) reports a set of clinical trials with the outcome of breast cancer detection. We want to build a method to predict whether a patient has a potential cancer or not according to her clinical trials.\n",
    "\n",
    "<p>\n",
    "\n",
    "For that purpose we will use two different models, a support vector machine and a gradient boosting machine. We will train different settings of a support vector machine (`svm.SVC`) and a single gradient boosting machine (`ensemble.GradientBoostingMachine`) with the following parameters:\n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "`svm.SVC(C=10.0,gamma = 1e-5,random_state=42)`\n",
    "</li>\n",
    "<li>\n",
    "`svm.SVC(C=100.0,gamma = 1e-5,random_state=42)`\n",
    "</li>\n",
    "<li>\n",
    "`svm.SVC(C=1000.0,gamma = 1e-6,random_state=42)`\n",
    "</li>\n",
    "<li>\n",
    "`ensemble.GradientBoostingClassifier(random_state=42)`\n",
    "</li>\n",
    "</ul>\n",
    "<p>\n",
    "For selection purposes and accuracy evaluation we will use `model_selection.train_test_split`.\n",
    "The data set will be divided using parameters `test_size = 100` and `random_state=42`. As a result of this first division we will have a big training set and a 100 samples test set. Following that and using the same settings we will divide the remaining training set into the final training set and the validation set with 100 samples again.\n",
    "\n",
    "    \n",
    "<p>\n",
    "    DO NOT PREPROCESS OR NORMALIZE DATA!\n",
    "<p>\n",
    "\n",
    "Prepare the following answers:\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "Check the sizes of the training, validation and test sets.\n",
    "</li>\n",
    "<li>\n",
    "Report the training accuracy of all four methods.\n",
    "</li>\n",
    "<li>\n",
    "Report the validation accuracy for all methods.\n",
    "</li>\n",
    "<li>\n",
    "Report the performance of all methods using the test set.\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "<p>\n",
    "In the light of the answers obtained from the exercise:\n",
    "<ul>\n",
    "<li>\n",
    "Question 1: What is the size of the training set? \n",
    "</li>\n",
    "<li>\n",
    "Question 2: What method do you select?\n",
    "</li>\n",
    "<li>\n",
    "Question 3: What is the expected performance of the method selected?\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
